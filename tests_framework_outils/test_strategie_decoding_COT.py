import os
import openai

# Assure-toi que ta cl√© est bien d√©finie ici ou dans ton environnement
openai.api_key = os.getenv("OPENAI_API_KEY")


def get_top_k_initial_tokens(prompt, k=3):
    """√âtape 1 ‚Äì Obtenir les top-k tokens initiaux avec leurs logprobs."""
    response = openai.chat.completions.create(
        model="gpt-4o",
        messages=[{"role": "user", "content": prompt}],
        max_tokens=1,
        temperature=0,
        logprobs=True,
        top_logprobs=k
    )

    # R√©cup√®re le 1er token g√©n√©r√© (objet ChatCompletionTokenLogprob)
    token_logprob = response.choices[0].logprobs.content[0]

    # Liste de (token, logprob) pour les top-k candidats
    top_k_tokens = [(t.token, t.logprob) for t in token_logprob.top_logprobs]
    return top_k_tokens


def generate_continuation(prompt, initial_token, max_tokens=100):
    """√âtape 2‚Äì4 ‚Äì G√©n√©rer la suite d‚Äôun prompt + token, et calculer le score logprob total."""
    new_prompt = f"{prompt} {initial_token}"
    response = openai.chat.completions.create(
        model="gpt-4o",
        messages=[{"role": "user", "content": new_prompt}],
        max_tokens=max_tokens,
        temperature=0.7,
        logprobs=True,
        top_logprobs=1
    )

    content = response.choices[0].message.content.strip()
    token_logprobs = [t for t in response.choices[0].logprobs.content]
    total_score = sum(t.logprob for t in token_logprobs)
    average_score = total_score / len(token_logprobs) if token_logprobs else float('-inf')
    return content, average_score, new_prompt


def decoding_cot_pipeline(prompt, k=3, max_tokens=100):
    print(f"üîç Prompt initial : {prompt}\n")

    top_k = get_top_k_initial_tokens(prompt, k=k)
    completions = []

    print(f"üéØ Top-{k} tokens initiaux :")
    for i, (token, logprob) in enumerate(top_k):
        print(f"{i + 1}. '{token}' (logprob = {logprob:.4f})")

    print("\nüß™ G√©n√©rations pour chaque token :")
    for i, (token, _) in enumerate(top_k):
        content, score, full_prompt = generate_continuation(prompt, token, max_tokens)
        completions.append((content, score, full_prompt))
        print(f"\n--- Option {i + 1} ---")
        print(f"Prompt utilis√© : {full_prompt}")
        print(f"Score logprobs : {score:.2f}")
        print(f"R√©ponse : {content}")

    best = max(completions, key=lambda x: x[1])

    print("\n‚úÖ Meilleure r√©ponse s√©lectionn√©e :")
    print(best[0])
    return best[0]


# Exemple
if __name__ == "__main__":
    decoding_cot_pipeline("Combien de R dans le mot Strawberry ?", k=3)

# Output:
# üîç Prompt initial : Combien de R dans le mot Strawberry ?
#
# üéØ Top-3 tokens initiaux :
# 1. 'Le' (logprob = -0.5768)
# 2. 'Il' (logprob = -1.0768)
# 3. 'Dans' (logprob = -2.3268)
#
# üß™ G√©n√©rations pour chaque token :
#
# --- Option 1 ---
# Prompt utilis√© : Combien de R dans le mot Strawberry ? Le
# Score logprobs : -0.77
# R√©ponse : Le mot "Strawberry" contient trois lettres "R".
#
# --- Option 2 ---
# Prompt utilis√© : Combien de R dans le mot Strawberry ? Il
# Score logprobs : -1.64
# R√©ponse : Le mot "Strawberry" contient trois "R".
#
# --- Option 3 ---
# Prompt utilis√© : Combien de R dans le mot Strawberry ? Dans
# Score logprobs : -1.10
# R√©ponse : Le mot "Strawberry" contient trois lettres "R".
#
# ‚úÖ Meilleure r√©ponse s√©lectionn√©e :
# Le mot "Strawberry" contient trois lettres "R".
